
<details>
<summary>

</summary>
<div>
</div>
</details>

### 운영체제

<details>
<summary>
운영체제란 무엇인가?
</summary>
<div>

운영체제는 컴퓨터 시스템의 자원을 효율적으로 관리하고 사용자에게 편리하고 효과적인 환경을 제공하는 시스템 소프트웨어입니다. 운영체제는 하드웨어와 사용자 응용 프로그램 사이의 중개자 역할을 하며, 컴퓨터 시스템의 자원을 효율적으로 할당하고 관리합니다.

#### 운영체제 역할
- 자원 관리: 운영체제는 컴퓨터의 하드웨어 자원(프로세서, 메모리, 디스크 공간, 입출력 장치 등)을 효율적으로 분배하고 관리합니다. 여러 프로그램과 사용자가 동시에 컴퓨터를 사용할 수 있도록 합니다.
- 프로세스 관리: 운영체제는 프로세스의 생성, 실행, 중지 등을 관리합니다. 프로세스 스케줄링을 통해 CPU 시간을 각 프로세스에 할당하고, 멀티태스킹 환경에서 여러 프로세스가 공정하게 자원을 사용할 수 있도록 합니다.
- 메모리 관리: 운영체제는 메모리 할당 및 회수를 관리하며, 가상 메모리 시스템을 통해 실제 메모리보다 더 큰 메모리 공간을 제공할 수 있습니다.
- 파일 시스템 관리: 파일과 디렉터리를 조직화하고 관리하는 기능을 제공합니다. 사용자와 응용 프로그램이 데이터를 저장하고 접근할 수 있도록 합니다.
- 입출력 시스템 관리: 키보드, 마우스, 디스플레이, 프린터 등 다양한 입출력 장치와의 통신을 관리합니다.
- 보안 및 접근 제어: 운영체제는 시스템 보안을 유지하기 위해 사용자 인증, 접근 권한 설정 등의 기능을 제공합니다.
</div>
</details>

<details>
<summary>
프로세스와 스레드의 차이는 무엇인가요?
</summary>
<div>

#### 프로세스(Process)
프로세스는 실행 중인 프로그램의 인스턴스입니다. 운영 체제가 메모리에 프로그램을 로드하고 실행할 때, 그 프로그램은 프로세스가 됩니다. 프로세스는 독립된 메모리 영역(코드, 데이터, 힙, 스택 등)을 가지며, 최소 하나의 스레드(메인 스레드)를 포함합니다. 프로세스들은 서로 독립적이기 때문에, 하나의 프로세스가 다른 프로세스의 자원에 직접 접근하는 것은 허용되지 않습니다. 이는 운영 체제가 제공하는 프로세스 간 통신(IPC) 기법을 사용하여 간접적으로만 가능합니다.

##### IPC란?
독립적인 프로세스들이 서로 데이터를 주고받거나 통신할 수 있도록 하는 메커니즘입니다. 파이프, 네임드 파이프, 메시지 큐, 세마포어, 공유 메모리, 소켓 방법이 존재합니다.

#### 스레드(Thread)
스레드는 프로세스 내에서 실행되는 실행의 단위입니다. 스레드는 프로세스의 자원을 공유하면서 동시에 실행될 수 있습니다. 각 스레드는 고유한 실행 흐름을 가지며, 자신만의 스택을 포함하지만, 코드, 데이터, 힙 영역은 프로세스 내의 다른 스레드와 공유합니다. 이러한 특성 때문에 스레드 간의 데이터 공유와 통신이 용이하지만, 동시성 문제를 일으킬 수 있습니다.

##### 차이점
- 메모리 공간: 프로세스는 독립된 메모리 영역을 가지는 반면, 스레드는 같은 프로세스 내에서 메모리(코드, 데이터, 힙)를 공유하고 고유한 스택만 가집니다.
- 자원의 독립성: 프로세스는 완전히 독립된 자원을 가지지만, 스레드는 일부 자원(힙 메모리 등)을 공유합니다.
- 생성과 관리의 비용: 일반적으로 프로세스를 생성하고 관리하는 비용이 스레드를 생성하고 관리하는 비용보다 더 큽니다.
- 통신 방법: 프로세스 간 통신(IPC)은 복잡하고 비용이 많이 드는 반면, 스레드 간 통신은 자원을 공유하기 때문에 더 간단하고 효율적입니다.
- 독립성: 프로세스는 완전히 독립적인 실행 단위로, 하나의 프로세스가 실패해도 다른 프로세스에 영향을 미치지 않습니다. 반면, 스레드는 프로세스 내에서 상대적으로 독립적이지만, 하나의 스레드에 문제가 생기면 같은 프로세스 내의 다른 스레드에 영향을 줄 수 있습니다.
</div>
</details>

<details>
<summary>
멀티 스레드와 멀티 프로세스의 차이는 무엇인가요?
</summary>
<div>

#### 멀티 프로세스
멀티 프로세스는 동시에 여러 프로세스를 실행하여 작업을 처리하는 방식입니다. 각 프로세스는 독립된 메모리 공간(코드, 데이터, 힙, 스택 등)을 가지며, 다른 프로세스와의 데이터 공유는 IPC(Inter-Process Communication)를 통해 이루어집니다. 멀티 프로세스 방식은 각 프로세스가 독립적으로 실행되기 때문에 안정성이 높고, 하나의 프로세스에 문제가 발생해도 다른 프로세스에는 영향을 주지 않습니다. 하지만, 프로세스 간의 커뮤니케이션 비용이 높고, 리소스(자원)의 소모가 크다는 단점이 있습니다.

#### 멀티 스레드
멀티 스레드는 하나의 프로세스 내에서 여러 스레드를 생성하여 동시에 작업을 처리하는 방식입니다. 스레드들은 프로세스 내의 코드, 데이터, 힙 영역을 공유하면서 각자의 스택을 가지고 독립적으로 실행됩니다. 멀티 스레드 방식은 스레드 간의 데이터 공유가 쉽고, 컨텍스트 스위칭(Context Switching) 비용이 낮아 리소스를 효율적으로 사용할 수 있다는 장점이 있습니다. 그러나, 스레드 간의 자원 공유로 인해 동기화 문제가 발생할 수 있으며, 하나의 스레드에 문제가 발생하면 전체 프로세스에 영향을 줄 수 있습니다.
</div>
</details>

<details>
<summary>
멀티 프로세스로 처리 가능한 걸 굳이 멀티 스레드로 하는 이유는?
</summary>
<div>

- 자원 공유: 멀티 스레드는 동일한 프로세스 내에서 메모리 공간(코드, 데이터, 힙)을 공유합니다. 이로 인해 스레드 간의 데이터 공유가 매우 효율적으로 이루어집니다. 반면, 멀티 프로세스는 각 프로세스가 독립된 메모리 공간을 가지므로, 프로세스 간 통신(IPC)을 위해 추가적인 오버헤드가 발생합니다.
- 오버헤드 감소: 멀티 스레드는 프로세스를 생성하고 관리하는 것보다 적은 오버헤드를 가집니다. 스레드 생성은 프로세스 생성보다 자원을 적게 소모하며, 컨텍스트 스위칭 시에도 더 효율적입니다. 이는 특히 자원이 제한된 시스템에서 중요한 이점입니다.
- 병렬 처리 효율성: 멀티 스레드는 CPU 코어를 효율적으로 활용하여 병렬 처리를 수행할 수 있습니다. 멀티 스레드 환경에서는 한 스레드가 블로킹 작업(예: I/O 작업)을 수행할 때, 다른 스레드가 CPU를 사용하여 계속 작업을 수행할 수 있습니다.
- 개발 및 유지보수 용이: 멀티 스레드는 프로세스 내에서 실행되므로, 프로세스 간 통신(IPC)이 필요하지 않으며 공유 메모리를 통한 데이터 공유가 직관적이며, 프로세스 간 통신보다 간단합니다.

그러나 멀티 스레드 환경은 스레드 간의 동기화 문제, 공유 자원에 대한 경쟁 상황(race condition) 등의 복잡성을 증가시키며, 하나의 스레드에서 발생한 오류가 전체 프로세스에 영향을 줄 수 있다는 단점도 있습니다.
</div>
</details>

<details>
<summary>
동기와 비동기의 차이 ?
</summary>
<div>

동기 방식은 작업 처리의 간결성과 예측 가능성을 제공하지만, 긴 작업 실행 시 시스템의 전반적인 반응성이 떨어질 수 있습니다. 반면, 비동기 방식은 동시에 여러 작업을 처리할 수 있어 효율적이지만, 작업 사이의 의존성 관리와 복잡한 구현이 요구됩니다. 따라서, 애플리케이션의 요구 사항과 특성에 따라 적절한 방식을 선택해야 합니다.

#### 동기(Synchronous)
- 동기 방식에서는 한 작업이 완료될 때까지 기다린 후 다음 작업을 실행합니다. 즉, 작업을 순차적으로 처리합니다.
##### 특징
- 작업의 완료를 기다리기 때문에 프로그램의 실행 흐름이 예측 가능합니다.
- 하나의 작업이 다른 작업의 시작을 차단(block)합니다.
- 구현이 비교적 단순하지만, 긴 작업이 있을 경우 전체 시스템의 효율성이 떨어질 수 있습니다.
#### 비동기(Asynchronous)
- 비동기 방식에서는 한 작업을 시작한 후, 그 작업이 끝나기를 기다리지 않고 즉시 다음 작업을 실행합니다. 작업의 완료 여부와 상관없이 다른 작업을 병행 처리할 수 있습니다.
##### 특징
- 작업의 완료를 기다리지 않기 때문에, 여러 작업을 동시에 처리할 수 있어 효율성이 높습니다.
- 작업 사이의 의존성 관리가 필요하며, 구현이 복잡할 수 있습니다.
- 이벤트 루프, 콜백 함수, 프로미스(Promise), async/await 등을 통해 구현됩니다.

</div>
</details>

<details>
<summary>
멀티 쓰레드 환경에서의 주의 사항 ?
</summary>
<div>

멀티 쓰레드 환경에서는 여러 쓰레드가 동시에 실행되므로, 자원 공유와 동시성 제어에 특별한 주의가 필요합니다.

- 공유 자원의 동시 접근 제어: 멀티 쓰레드 환경에서 여러 쓰레드가 공유 자원에 동시에 접근할 때, 데이터의 일관성과 무결성을 유지하기 위해 동기화 기법이 필요합니다. mutex나 semaphore 같은 동기화 메커니즘을 사용하여 자원 접근을 제어해야 합니다.
- 데드락(Deadlock) 방지: 두 개 이상의 쓰레드가 서로 다른 쓰레드의 작업 완료를 무한히 기다리는 상황을 데드락이라고 합니다. 데드락을 방지하기 위해서는 자원 할당 순서를 일관되게 유지하고, 필요하지 않은 자원은 빠르게 해제하며, 필요한 최소한의 자원만을 잠그도록 해야 합니다.
- 스레드 기아(Starvation): 일부 쓰레드가 자원에 접근하지 못하고 무한히 대기하는 상황입니다. 이를 방지하기 위해서는 공정한 자원 분배 정책을 사용하고, 우선순위 부여에 주의해야 합니다.
- 컨텍스트 스위칭(Context Switching) 비용 인식: 쓰레드는 경량 프로세스로 비교적 컨텍스트 스위칭 비용이 낮지만, 쓰레드의 수가 많아지면 이 비용이 상당히 증가할 수 있습니다. 쓰레드를 너무 많이 생성하지 않도록 주의하고, 쓰레드 풀을 사용하는 등의 방법으로 최적화할 수 있습니다.
- 메모리 관리 주의: 멀티 쓰레드 환경에서는 동적으로 할당된 메모리를 공유 자원으로 사용할 때 해제 시점을 정확히 관리해야 합니다. 잘못된 메모리 해제는 메모리 누수나 무효 메모리 접근을 초래할 수 있습니다.
- 레이스 컨디션(Race Condition) 방지: 레이스 컨디션은 여러 쓰레드가 데이터를 동시에 읽고 쓰려고 할 때 발생하는 문제로, 결과의 정확성을 보장할 수 없습니다. 변수 접근 시 동기화를 통해 이를 방지해야 합니다.
</div>
</details>

<details>
<summary>
교착상태(DeadLock)가 무엇이며, 4가지 조건은?
</summary>
<div>

교착상태(Deadlock)는 멀티태스킹 시스템에서 두 개 이상의 프로세스나 스레드가 서로의 실행을 무한히 기다리는 상태를 말합니다. 이 상태에 이르면, 각 프로세스는 다른 프로세스가 자원을 해제하기를 기다리고 있기 때문에 시스템이 멈춰버리게 됩니다.
##### 데드락 조건
- 상호 배제(Mutual Exclusion): 한 번에 하나의 프로세스만이 자원을 사용할 수 있습니다. 다른 프로세스는 그 자원이 해제될 때까지 기다려야 합니다.
- 보유 대기(Hold and Wait): 프로세스가 어떤 자원을 보유한 상태에서 다른 자원을 기다립니다.
- 비선점(No Preemption): 프로세스가 자원을 스스로 해제하기 전까지는 다른 프로세스가 그 자원을 강제로 빼앗을 수 없습니다.
- 순환 대기(Circular Wait): 각 프로세스가 순환적으로 다음 프로세스가 요구하는 자원을 보유하고 있어, 서로가 서로의 자원을 기다리는 상태가 됩니다.

##### 데드락 해결법
- prevention: 4가지중 하나를 부정
- avoidance: safe state(데드락이 발생하지 않는 상태 즉, 자원이 충분한 상태), safe sequence(데드락이 발생하지 않은 순서) ex)은행원 알고리즘 - 미리 결정된 모든 자원들의 최대 가능한 할당량을 가지고 시뮬레이션 해서 Safe state에 들 수 있는지 여부를 검사
- detection and recovery: 시스템의 자원 할당 상태를 가지고 데드락 발생 여부 판단, 프로세스 1개 이상 중단 or 자원 선점

https://chanhuiseok.github.io/posts/cs-2/
</div>
</details>

<details>
<summary>
가상 메모리란?
</summary>
<div>

가상 메모리는 컴퓨터 시스템에서 사용되는 메모리 관리 기술입니다. 이 기술은 프로그램이 사용할 수 있는 메모리 양을 물리적 메모리(주로 RAM)의 크기에 제한되지 않게 하여, 더 큰 메모리 공간을 제공하는 것처럼 만듭니다. 가상 메모리는 물리적 메모리와 보조 저장 장치(예: 하드 드라이브 또는 SSD)를 함께 사용하여 구현됩니다.

##### 주요 개념 및 작동 원리

- 가상 주소 공간: 각 프로세스는 독립된 가상 주소 공간을 갖습니다. 이 공간은 실제 물리적 메모리 주소와는 별개로, 프로세스에 의해 참조되는 메모리 주소입니다.
- 페이지: 가상 메모리는 페이지라는 작은 고정 크기의 블록으로 나뉩니다. 물리적 메모리도 같은 크기의 페이지 프레임으로 나누어집니다.
- 페이지 매핑: 운영 체제는 페이지 테이블을 사용하여 가상 페이지와 물리적 페이지 프레임 간의 매핑을 관리합니다. 이를 통해 프로세스가 가상 주소를 사용해 메모리에 접근할 때, 실제 물리적 주소로 변환될 수 있습니다.
- 스와핑: 사용되지 않는 페이지는 보조 저장 장치로 옮겨지는데, 이 과정을 스와핑이라고 합니다. 필요할 때 다시 물리적 메모리로 가져올 수 있습니다. 이를 통해 제한된 물리적 메모리를 보다 효율적으로 사용할 수 있습니다.
- 페이지 폴트: 프로그램이 접근하려는 페이지가 물리적 메모리에 없을 경우, 페이지 폴트가 발생합니다. 운영 체제는 해당 페이지를 보조 저장 장치에서 찾아 물리적 메모리로 로드합니다.

</div>
</details>

<details>
<summary>
외부 단편화와 내부 단편화란?
</summary>
<div>

#### 외부 단편화(External Fragmentation)
- 외부 단편화는 메모리 공간에 충분한 여유 공간이 있지만, 그 공간이 연속적이지 않아 프로세스를 할당할 수 없는 상황을 말합니다.
- 예를 들어, 메모리에 10MB, 5MB, 3MB의 빈 공간이 있다고 가정해 봅시다. 이 경우 총 18MB의 여유 공간이 있지만, 프로세스가 필요로 하는 8MB의 메모리를 할당할 수 없습니다. 이처럼 메모리 공간이 연속적이지 않아 발생하는 문제가 외부 단편화입니다.

#### 내부 단편화(Internal Fragmentation)
- 내부 단편화는 프로세스가 필요로 하는 메모리 크기보다 실제 할당된 메모리 크기가 더 큰 경우에 발생합니다. 이로 인해 할당된 메모리 공간 중 일부가 사용되지 않고 남게 되는 현상입니다.

- 예를 들어, 프로세스가 4MB의 메모리를 필요로 하지만, 운영체제가 8MB의 메모리 블록을 할당했다고 가정해 봅시다. 이 경우 4MB의 메모리가 사용되지 않고 남게 되는데, 이것이 내부 단편화입니다.

##### 단편화 해결 방법
- 압축(Compaction): 외부 단편화를 해결하기 위해 메모리 내의 빈 공간을 모아 하나의 큰 공간을 만드는 기법입니다.
- 동적 할당(Dynamic Allocation): 프로세스의 메모리 요구량에 따라 동적으로 메모리를 할당하여 내부 단편화를 줄일 수 있습니다.
- 페이징(Paging): 프로세스를 페이지 단위로 나누어 관리함으로써 단편화를 방지할 수 있습니다.
- 세그먼테이션(Segmentation): 프로세스를 논리적 단위인 세그먼트로 나누어 관리함으로써 단편화를 줄일 수 있습니다.

##### Appendix 가상 메모리와 단편화
가상 메모리 기술은 단편화 문제를 해결하는 데 도움이 됩니다. 가상 메모리는 물리 메모리와 논리 메모리를 분리하여 관리함으로써, 프로세스가 실제 물리 메모리 크기를 초과하여 실행될 수 있도록 합니다. 이를 통해 단편화로 인한 메모리 할당 문제를 해결할 수 있습니다.

또한 가상 메모리 시스템에서는 MMU(Memory Management Unit)가 논리 주소를 물리 주소로 변환하는 역할을 수행합니다. 이를 통해 프로세스는 실제 물리 메모리 구조를 인식하지 않고도 메모리를 사용할 수 있습니다.
</div>
</details>

<details>
<summary>
페이징과 세그먼테이션이란?
</summary>
<div>

#### 페이징 (Paging)
페이징은 물리적 메모리를 고정된 크기의 작은 블록으로 나누는 방식입니다. 이러한 블록들을 페이지(논리적 메모리에서는 페이지로 나누고 물리적 메모리는 프레임으로 나눠서 매칭)라고 하며, 물리적 메모리의 페이지와 동일한 크기의 가상 메모리 페이지로 프로세스의 주소 공간을 분할합니다. 페이징에서는 가상 메모리 주소가 물리적 메모리 주소로 변환될 때 페이지 테이블을 사용하여 변환합니다. 페이징 기법의 주요 장점은 내부 단편화를 줄일 수 있다는 점과 메모리 관리가 단순해진다는 점입니다. 하지만 모든 페이지가 동일한 크기이기 때문에, 프로세스의 메모리 요구 사항에 딱 맞지 않는 경우가 생길 수 있으며, 이로 인해 약간의 내부 단편화가 발생할 수 있습니다.

![process](image.png)
#### 세그먼테이션 (Segmentation)
세그먼테이션은 프로세스의 주소 공간을 논리적으로 의미 있는 여러 세그먼트로 분할하는 방식입니다. 예를 들어, 코드, 데이터, 스택 등으로 분리할 수 있습니다. 각 세그먼트는 시작 주소와 길이를 가지며, 이를 통해 메모리에 할당됩니다. 세그먼테이션의 주요 장점은 메모리를 더 유연하게 관리할 수 있다는 것입니다. 프로그램의 논리적 구조에 따라 메모리를 할당할 수 있기 때문에, 개발자가 메모리를 효율적으로 사용할 수 있도록 도와줍니다. 하지만, 세그먼테이션은 외부 단편화 문제를 야기할 수 있으며, 세그먼트의 크기가 다양하기 때문에 메모리 관리가 복잡해질 수 있습니다.

##### 요약
페이징은 메모리를 고정된 크기의 페이지로 나누고, 내부 단편화를 줄이며 메모리 관리를 단순화합니다.
세그먼테이션은 메모리를 논리적 단위인 세그먼트로 나누어 더 유연한 메모리 관리를 가능하게 하지만, 외부 단편화와 복잡한 메모리 관리 문제를 가질 수 있습니다.
</div>
</details>

<details>
<summary>
비선점형(Non-preemptive) 스케줄링
</summary>
<div>

비선점형(Non-preemptive) 스케줄링은 컴퓨터 운영체제의 중요한 작업 스케줄링 방식 중 하나입니다. 이 방식에서는 한 번 CPU(중앙 처리 장치)가 작업(프로세스 또는 스레드)에 할당되면, 해당 작업이 완료되거나, I/O(입출력) 작업 등으로 대기 상태가 될 때까지 CPU를 계속 사용하게 됩니다. 즉, 작업이 실행 중일 때 다른 작업으로 CPU를 강제로 빼앗는 것이 허용되지 않습니다.

##### 특징
- 프로세스가 CPU 사용을 완료하거나 I/O 작업을 요청할 때까지 CPU 제어권을 가짐
- 프로세스 간 우선순위 고려 없이 FIFO(First-In-First-Out) 방식으로 CPU 할당
- 프로세스 전환 시 문맥 교환(Context Switching) 오버헤드가 낮음
##### 장점
- 프로세스 간 공정성 보장
- 응답 시간 예측 가능
- 문맥 교환 오버헤드 감소
##### 단점
- 높은 우선순위 프로세스가 대기해야 하는 상황 발생 가능
- 실시간 시스템에 적합하지 않음
- 프로세스 간 우선순위 고려 불가
</div>
</details>

<details>
<summary>
선점형(preemptive) 스케줄링
</summary>
<div>

선점형 스케줄링은 프로세스가 CPU를 사용하는 도중에도 운영체제가 CPU 제어권을 강제로 회수할 수 있는 방식입니다. 즉, 프로세스가 CPU를 점유하고 있더라도 운영체제가 필요에 따라 CPU 제어권을 회수할 수 있습니다.

##### 특징
- 프로세스 간 우선순위에 따라 CPU 제어권 강제 회수 가능
- 문맥 교환(Context Switching) 오버헤드가 비선점형 스케줄링보다 높음
- 실시간 시스템에 적합한 스케줄링 방식
##### 장점
- 높은 우선순위 프로세스에 CPU 자원 신속 할당 가능
- 실시간 시스템에 적합
##### 단점
- 문맥 교환 오버헤드 증가
- 프로세스 간 공정성 보장이 어려움

##### 선점형 스케줄링 알고리즘
- 라운드 로빈(Round Robin, RR) 스케줄링:
  - 각 프로세스에 동일한 시간 할당(Time Slice)
  - 시간 할당이 끝나면 강제로 CPU 제어권 회수
  - 공정성이 높지만 응답 시간이 길어질 수 있음
- 최단 잔여 시간 우선(Shortest Remaining Time, SRT) 스케줄링:
  - 남은 실행 시간이 가장 짧은 프로세스에 CPU 할당
  - 새로운 프로세스가 도착하면 현재 실행 중인 프로세스를 선점할 수 있음
  - 평균 대기 시간이 짧지만 실행 시간이 긴 프로세스에 불리할 수 있음
- 다단계 피드백 큐(Multilevel Feedback Queue, MFQ) 스케줄링:
  - 여러 개의 준비 큐를 사용하여 우선순위를 관리(같은 우선순위 안에서는 라운드 로빈)
  - 프로세스가 CPU를 오래 사용하면 우선순위가 낮아짐
  - 대화형 프로세스와 배치 프로세스를 구분하여 효율적으로 관리
</div>
</details>

<details>
<summary>
인터럽트란 무엇인가요?
</summary>
<div>

인터럽트는 컴퓨터 시스템에서 중요한 개념으로, 현재 진행 중인 작업을 일시 중단시키고, 긴급하게 처리해야 할 작업(인터럽트 요청에 의해 발생한 작업)을 먼저 처리한 후, 원래의 작업으로 돌아가게 하는 메커니즘입니다. 인터럽트는 컴퓨터 하드웨어나 소프트웨어에 의해 발생할 수 있으며, 시스템의 효율성과 반응성을 향상시키는 데 중요한 역할을 합니다.

##### 인터럽트의 종류
- 하드웨어 인터럽트: 외부 장치(키보드, 마우스, 네트워크 카드 등)로부터 발생하는 인터럽트입니다. 예를 들어, 사용자가 키보드를 누를 때마다 하드웨어 인터럽트가 발생하여 CPU에 입력 처리를 요청합니다.
- 소프트웨어 인터럽트: 운영 체제나 실행 중인 프로그램 내부에서 발생하는 인터럽트입니다. 예를 들어, 시스템 호출이나 예외 처리 과정에서 발생할 수 있습니다.
##### 인터럽트 처리 과정
- 인터럽트 발생: 시스템 내부 또는 외부에서 인터럽트 신호가 발생합니다.
- 현재 작업 중단: CPU는 현재 처리 중인 작업을 일시 중단하고, 작업의 현재 상태를 저장합니다.
- 인터럽트 처리 루틴 실행: 인터럽트 벡터를 사용하여 해당 인터럽트를 처리할 루틴(함수, ISR)을 찾아 실행합니다.
- 원래 작업 복귀: 인터럽트 처리가 완료되면, 중단되었던 원래의 작업 상태를 복원하고 작업을 재개합니다.
##### 인터럽트의 중요성
- 멀티태스킹 지원: 인터럽트를 통해 여러 작업을 효율적으로 동시에 처리할 수 있습니다.
- 시스템 반응성 향상: 긴급한 작업이 발생했을 때 즉각적으로 대응할 수 있어 사용자 경험을 향상시킵니다.
- 자원 효율적 사용: 인터럽트를 이용하여 CPU와 다른 자원들을 보다 효율적으로 사용할 수 있습니다
</div>
</details>

<details>
<summary>
운영체제한테 CPU가 넘어가는 경우는 언제인가?
</summary>
<div>

1. 인터럽트(Interrupt) 발생 시: 하드웨어나 소프트웨어에서 발생한 인터럽트 신호를 처리하기 위해 운영체제가 CPU 제어권을 넘겨받습니다. 예를 들어, 입출력 장치로부터의 요청, 타이머 인터럽트, 네트워크 카드로부터의 신호 등이 이에 해당합니다.

2. 시스템 콜(System Call) 실행 시: 사용자 프로그램이 운영체제의 서비스를 요청하기 위해 시스템 콜을 실행하면, 해당 서비스를 처리하기 위해 운영체제가 CPU 제어권을 넘겨받습니다. 파일 열기, 읽기, 쓰기, 네트워크 통신 등의 작업이 시스템 콜을 통해 수행됩니다.

3. 프로세스 스케줄링: 운영체제는 프로세스 간 CPU 사용 시간을 공정하게 분배하기 위해 스케줄링을 수행합니다. 현재 실행 중인 프로세스의 시간 할당량(타임 슬라이스)이 끝나거나 우선 순위가 더 높은 프로세스가 준비 상태가 되면, 운영체제는 스케줄러를 통해 CPU 제어권을 넘겨받아 새로운 프로세스로 전환합니다.

4. 예외 상황(Exception) 발생 시: 소프트웨어 오류나 금지된 작업(예: 0으로 나누기, 잘못된 메모리 접근)이 발생했을 때, 운영체제는 예외 처리 루틴을 실행하기 위해 CPU 제어권을 넘겨받습니다.
</div>
</details>

<details>
<summary>
인터럽트 처리중에 또다른 인터럽트가 발생하는 경우는 어떻게 되는가?
</summary>
<div>

인터럽트 처리 중에 또 다른 인터럽트가 발생하는 경우, 시스템은 인터럽트의 우선 순위에 따라 처리 방식을 결정합니다. 이를 인터럽트 중첩(Interrupt Nesting)이라고 하며, 인터럽트 처리의 효율성과 반응성을 높이기 위해 사용됩니다. 처리 방식은 대체로 다음과 같습니다:

- 우선 순위가 낮은 인터럽트 처리 중에 우선 순위가 높은 인터럽트가 발생하는 경우: 시스템은 현재 처리 중인 인터럽트를 일시 중단하고, 더 높은 우선 순위의 인터럽트를 먼저 처리합니다. 이 과정을 통해 중요한 작업을 더 신속하게 처리할 수 있습니다.

- 우선 순위가 같은 인터럽트가 발생하는 경우: 대부분의 시스템에서는 같은 우선 순위의 인터럽트가 동시에 발생하면, 일반적으로 현재 처리 중인 인터럽트를 먼저 완료하고, 그 다음에 대기 중인 인터럽트를 처리합니다.

- 우선 순위가 높은 인터럽트 처리 중에 우선 순위가 낮은 인터럽트가 발생하는 경우: 우선 순위가 낮은 인터럽트는 현재 처리 중인 높은 우선 순위의 인터럽트 처리가 완료될 때까지 대기하게 됩니다.

- 여러 장치에서 인터럽트가 동시에 발생하거나 인터럽트 서비스 루틴 수행 중 인터럽트가 발생한 경우 우선순위 판별 필요
  1. 전원 이상(Power fail)
  2. 기계 착오(Machine Check)
  3. 외부 신호(External)
  4. 입출력(I/O)
  5. 명령어 잘못
  6. 프로그램 검사(Program Check)
  7. SVC(SuperVisor Call)
일반적으로 하드웨어 인터럽트가 소프트웨어 인터럽트보다 우선 순위가 높고, 일반적으로 내부 인터럽트 보다 외부 인터럽트가 우선 순위가 높다.

</div>
</details>

<details>
<summary>
PCB란 무엇인가요?
</summary>
<div>

#### PCB(Process Control Block)
- PCB는 운영 체제 커널의 데이터 구조로, 특정 프로세스를 관리하는 데 필요한 정보를 포함하고 있습니다.
- PCB에는 프로세스 식별자, 프로세스 상태, 프로그램 카운터, CPU 레지스터, CPU 스케줄링 정보, 메모리 관리 정보, 계정 정보, 입출력 상태 정보 등이 포함됩니다.
- PCB는 운영 체제에 의해 보호된 메모리 영역에 위치하며, 일부 운영 체제에서는 커널 스택의 처음에 위치합니다.
##### PCB의 역할과 중요성
- PCB는 운영 체제가 프로세스를 효과적으로 관리하고 제어하는 데 필수적인 역할을 합니다.
- 프로세스 생성 시 PCB가 만들어지며, 프로세스의 상태 정보를 저장하고 관리합니다.
- 프로세스 간 전환(context switching) 시 현재 프로세스의 정보를 PCB에 저장하고, 새로운 프로세스의 정보를 PCB에서 읽어 CPU 레지스터에 로드합니다.
##### PCB의 구성 요소
- 프로세스 식별자(PID): 프로세스를 고유하게 식별하는 번호
- 프로세스 상태: 실행 중, 대기 중, 준비 중 등 프로세스의 현재 상태
- 프로그램 카운터: 다음에 실행할 명령어의 주소
- CPU 레지스터: 프로세스 실행에 필요한 CPU 레지스터 값
- CPU 스케줄링 정보: 프로세스 우선순위, 실행 시간 등 스케줄링 관련 정보
- 메모리 관리 정보: 프로세스가 사용하는 메모리 영역 정보
- 계정 정보: 프로세스 실행 시간, 자원 사용량 등 계정 정보
- 입출력 상태 정보: 프로세스의 입출력 작업 상태
##### PCB와 Context Switching
Context Switching은 현재 프로세스의 PCB 정보를 저장하고, 새로운 프로세스의 PCB 정보를 로드하는 과정입니다.
인터럽트 처리나 새로운 프로세스 할당 등의 요청이 있을 때 Context Switching이 발생합니다.
Context Switching은 프로세스 간 전환을 원활하게 하여 운영 체제의 효율적인 프로세스 관리를 가능하게 합니다.

</div>
</details>

<details>
<summary>
PCB는 왜 필요한가요?
</summary>
<div>

- 프로세스 관리: PCB에는 프로세스의 상태 정보와 실행에 필요한 다양한 정보가 포함되어 있습니다. 이를 통해 운영 체제는 프로세스를 생성, 중지, 일시 중지, 재개 등의 작업을 수행할 수 있습니다.
- 프로세스 간 전환(Context Switching): PCB는 Context Switching 과정에서 사용됩니다. 현재 프로세스의 정보를 PCB에 저장하고, 새로운 프로세스의 정보를 PCB에서 읽어 CPU 레지스터에 로드합니다. 이를 통해 여러 프로세스 간의 공정한 시간 분배와 운영 체제의 효율적인 관리가 가능해집니다.
- 자원 할당 및 관리: PCB에는 프로세스가 사용하는 메모리 영역 정보, 계정 정보, 입출력 상태 정보 등이 포함되어 있습니다. 이를 통해 운영 체제는 자원을 효율적으로 할당하고 관리할 수 있습니다.
- 프로세스 식별: PCB에는 프로세스를 고유하게 식별하는 번호(PID)가 포함되어 있습니다. 이를 통해 운영 체제는 각 프로세스를 식별하고 구분할 수 있습니다.
</div>
</details>

<details>
<summary>
Context Swiching이란 무엇인가요?
</summary>
<div>

컨텍스트 스위칭(Context Switching)은 운영 체제가 CPU를 사용하는 한 프로세스에서 다른 프로세스로 전환하는 과정을 말합니다. 이 과정은 멀티태스킹 환경에서 여러 프로세스나 스레드가 CPU 시간을 공유할 수 있게 해 주며, 시스템의 효율성과 반응성을 높이는 데 중요한 역할을 합니다.

##### 컨텍스트 스위칭 과정
- 현재 실행 중인 프로세스의 상태 저장: 운영 체제는 현재 CPU를 사용하고 있는 프로세스의 상태(레지스터 값, 프로그램 카운터, 스택 포인터 등)를 해당 프로세스의 PCB(Process Control Block)에 저장합니다. 이를 통해 프로세스가 나중에 다시 실행될 때 이전에 중단된 지점부터 정확히 실행을 재개할 수 있습니다.
- 다음 실행할 프로세스의 상태 복원: 운영 체제는 다음에 실행할 프로세스의 PCB에서 저장된 상태를 읽어들여 CPU의 레지스터와 다른 제어 레지스터에 복원합니다. 이로써 새로운 프로세스가 실행될 준비가 완료됩니다.
- 실행 전환: CPU는 이제 새로운 프로세스의 실행을 시작합니다.

컨텍스트 스위칭은 필수적인 작업이지만, 자원을 소모하는 작업입니다. 컨텍스트를 저장하고 복원하는 과정에서 시간이 소요되며, 이로 인해 CPU의 유휴 시간이 발생할 수 있습니다. 따라서 운영 체제는 컨텍스트 스위칭을 효율적으로 관리하여 시스템의 전반적인 성능을 최적화하려고 노력합니다.
</div>
</details>

<details>
<summary>
사용자 수준 스레드 vs 커널 수준 스레드 차이는?
</summary>
<div>

#### 사용자 수준 스레드(User-Level Threads, ULT)
- 관리: 사용자 수준의 스레드 라이브러리에 의해 관리됩니다. 커널은 이러한 스레드의 존재를 알지 못합니다.
- 성능: 커널 개입 없이 스레드를 생성하고 관리할 수 있으므로, 컨텍스트 스위칭이 빠르고 효율적입니다.
- 자원 할당: 프로세스 단위로 자원을 할당받으며, 하나의 스레드가 블록되면 다른 스레드에 영향을 줄 수 있습니다.
- 구현과 이식성: 특정 운영 체제에 의존하지 않으므로 다양한 시스템에 쉽게 이식할 수 있습니다.
#### 커널 수준 스레드(Kernel-Level Threads, KLT)
- 관리: 운영 체제의 커널에 의해 직접 관리됩니다. 커널은 각 스레드를 개별적으로 인식하고 스케줄링합니다.
- 성능: 스레드 관리를 위해 커널 모드로의 전환을 필요로 하므로, 사용자 수준 스레드에 비해 컨텍스트 스위칭이 느릴 수 있습니다.
- 자원 할당: 각 스레드는 독립적으로 자원을 할당받으며, 하나의 스레드가 블록되더라도 다른 스레드는 영향을 받지 않습니다.
- 구현과 이식성: 운영 체제의 지원을 필요로 하므로, 특정 시스템에 종속적일 수 있습니다.
</div>
</details>

<details>
<summary>
뮤텍스, 세마포어가 뭔지, 차이점은?
</summary>
<div>

#### 뮤텍스(Mutex)
- 뮤텍스는 상호 배제(Mutual Exclusion)를 위한 동기화 기법입니다.
- 공유 자원에 대한 접근을 한 번에 하나의 스레드/프로세스만 허용하여, 데이터 불일치 문제를 방지합니다.
- 뮤텍스는 임계 영역(Critical Section)에 대한 접근을 제어하는 역할을 합니다.
- 뮤텍스는 잠금(Lock)과 해제(Unlock) 함수를 통해 구현됩니다.
#### 세마포어(Semaphore)
- 세마포어는 공유 자원에 대한 접근을 제어하는 동기화 기법입니다.
- 세마포어는 정수 값을 사용하여 자원의 가용성을 나타냅니다.
- 세마포어는 자원을 요청하는 스레드/프로세스에게 자원을 할당하거나 대기열에 넣는 역할을 합니다.
- 세마포어는 wait()와 signal() 함수를 통해 구현됩니다.

##### 차이점
- 접근 제어 방식
  - 뮤텍스는 한 번에 하나의 스레드/프로세스만 접근할 수 있도록 제한합니다.
  - 세마포어는 정수 값을 사용하여 여러 스레드/프로세스가 동시에 접근할 수 있도록 합니다.
- 구현 방식
  - 뮤텍스는 잠금(Lock)과 해제(Unlock) 함수를 사용하여 구현됩니다.
  - 세마포어는 wait()와 signal() 함수를 사용하여 구현됩니다.
- 용도
  - 뮤텍스는 공유 자원에 대한 상호 배제를 위해 사용됩니다.
  - 세마포어는 공유 자원에 대한 동기화를 위해 사용됩니다.
</div>
</details>

<details>
<summary>
프로세스의 스택, 데이터, 코드, 힙에 대해 설명해주세요.
</summary>
<div>

1. 코드(Code) 영역
- 사용자가 작성한 프로그램 코드가 저장되는 영역
- CPU가 실행할 수 있는 기계어 명령어 형태로 저장됩니다.
- 읽기 전용(Read-Only)으로 실행 중에는 변경할 수 없습니다.
2. 데이터(Data) 영역
- 전역 변수, static 변수 등 프로그램이 사용하는 데이터가 저장되는 영역
- 초기화된 데이터(Data Segment)와 초기화되지 않은 데이터(BSS Segment)로 구분됩니다.
3. 스택(Stack) 영역
- 함수 호출 시 전달되는 매개변수, 지역 변수, 복귀 주소 등이 저장되는 영역
- 후입선출(LIFO) 구조를 가지며, 함수 호출/반환 시 동적으로 메모리가 할당/해제됩니다.
4. 힙(Heap) 영역
- 동적으로 메모리를 할당/해제하는 데 사용되는 영역
- 프로그래밍 언어의 동적 메모리 할당 기능(malloc, new 등)에 의해 사용됩니다.

##### 메모리 영역의 특징
- 코드 영역과 데이터 영역은 프로그램 실행 중 변경될 수 없는 정적 영역입니다.
- 스택과 힙은 동적으로 메모리가 할당/해제되는 영역입니다.
- 스택은 함수 호출 시 빠르게 메모리를 할당/해제할 수 있지만, 크기가 제한적입니다.
- 힙은 동적 메모리 할당이 가능하지만, 스택보다 느리고 메모리 관리가 복잡합니다.
</div>
</details>

<details>
<summary>
4 CPU 환경에서 4개의 쓰레드가 실행된다고 가정해보자. 어떤 문제가 발생할 수 있겠는가?
</summary>
<div>

- 경쟁 상태(Race Condition): 여러 쓰레드가 동시에 공유 자원에 접근하려고 할 때, 그 접근 순서에 따라 실행 결과가 달라질 수 있습니다. 이러한 상황을 경쟁 상태라고 하며, 데이터가 예기치 않게 변경되거나 손상될 위험이 있습니다.
- 교착 상태(Deadlock): 두 개 이상의 쓰레드가 서로가 보유한 자원의 해제를 무한정 기다리며, 어떤 쓰레드도 진행할 수 없는 상태입니다. 예를 들어, 쓰레드 A가 자원 1을 보유하고 자원 2를 요청하는 동안, 쓰레드 B가 자원 2를 보유하고 자원 1을 요청할 때 교착 상태가 발생할 수 있습니다.
- 메모리 일관성 문제(Memory Consistency Issues): 여러 쓰레드가 공유 메모리를 동시에 수정할 때, 메모리의 일관성을 유지하기 위한 추가적인 메커니즘이 필요합니다. 이러한 메커니즘 없이는 예측 불가능한 결과를 초래할 수 있습니다.
</div>
</details>


